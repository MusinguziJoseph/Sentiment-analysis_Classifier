# -*- coding: utf-8 -*-
"""SENTIMENT ANALYZER 02 WORKING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dwDnt6ZuhsrTBknViFN3k5ueVpTsu8cl
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from sklearn.utils import resample
from wordcloud import WordCloud, STOPWORDS

import os

# reading the data
data= pd.read_csv('flipkart_product.csv',encoding='unicode_escape')

#  dropping empty rows/records
data.dropna(inplace=True)
data.info()

# looks like Rate column has some text data, let us remove it and keep only rating values which are integer
data=data[(data['Rate'] == '5') | (data['Rate'] == '4') | (data['Rate'] == '3') | (data['Rate'] == '2') | (data['Rate'] == '1') ]

data['Rate'].value_counts()

# lets pre-process text columns and remove noise and drop Price ColumnÂ¶
def preprocess(row):
    row=re.sub('[^a-zA-Z0-9]', ' ', row)
    row= re.sub('\s+', ' ', row)
    return row

data['Review']=data['Review'].apply(lambda x: preprocess(x))
data['Summary']=data['Summary'].apply(lambda x: preprocess(x))
data['ProductName']=data['ProductName'].apply(lambda x: preprocess(x))
data.drop(['Price'],axis=1,inplace=True)

#let us reduce number of lables from 5 to 3 (positive(5,4), neutral(3) and Negative(2,1) )
sentiment_map={'5':'positive','4':'positive','2':'negative','1':'negative', '3':'neutral'}
data['Sentiment']=data['Rate'].map(sentiment_map)

sns.countplot(data, x='Sentiment')

# Down sample Positive class and balance the data
bad_reviews = data[data['Sentiment']=='negative']
nue_reviews=data[data['Sentiment'] == 'neutral']
good_reviews=data[data['Sentiment']=='positive']

good_reviews_text=' '.join (good_reviews['Summary'].to_numpy().tolist())
bad_reviews_text = " ".join(bad_reviews['Summary'].to_numpy().tolist())
nue_reviews_text=" ".join(nue_reviews['Summary'].to_numpy().tolist())

good_reviews_down_sample=resample(good_reviews, n_samples=len(bad_reviews), replace=False)
good_reviews_down_sample_text=" ".join(good_reviews_down_sample.Summary.to_numpy().tolist())

#let us plot word cloud to understand imp words in each classes
# generate Word Cloud
def gen_wc(txt):
    stopwords = set(STOPWORDS)
    # crisp wordcloud : https://stackoverflow.com/a/28795577/11105356
    wc = WordCloud(width=800, height=400,background_color="white", max_font_size=300, stopwords = stopwords).generate(txt)
    plt.figure(figsize=(14,10))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis('off')
    plt.show()

# plotting  word cloud for positive Class, down sampled positive class, negative class and Neutral class
gen_wc(good_reviews_text)

gen_wc(good_reviews_down_sample_text)

gen_wc(nue_reviews_text)

gen_wc(bad_reviews_text)

# lets use down sampled data for further modelling
balanced_data=pd.concat([bad_reviews,nue_reviews,good_reviews_down_sample],axis=0)
balanced_data['Sentiment'].value_counts()

# plot count graph after balancing the data
sns.countplot(balanced_data, x='Rate')

sns.countplot(balanced_data, x='Sentiment')

# Let us encode the lables into integers and split the data into train and tes
from sklearn.preprocessing import LabelEncoder
label_enc=LabelEncoder()
balanced_data['Sentiment']=label_enc.fit_transform(balanced_data['Sentiment'])

# before to train test split let us merge Review and Summary col. which will be considered as out feature col
balanced_data['comments']=balanced_data['Review'] +" " + balanced_data['Summary']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(balanced_data['comments'], balanced_data['Sentiment'], test_size=0.3)

# Embedding of the data
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer

tfidf=TfidfVectorizer()
tfidf.fit(balanced_data['comments'])

tf_x_train=tfidf.transform(x_train)
tf_x_test=tfidf.transform(x_test)

cnvec=CountVectorizer()
cnvec.fit(balanced_data['comments'])

cn_x_train=cnvec.transform(x_train)
cn_x_test=cnvec.transform(x_test)

from sklearn.svm import SVC
# Training the SVM model with TF-IDF features
svm_model_tfidf = SVC(kernel='linear')
svm_model_tfidf.fit(tf_x_train, y_train)

# Making predictions
tfidf_predictions = svm_model_tfidf.predict(tf_x_test)

# Evaluating the model
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("TF-IDF Accuracy:", accuracy_score(y_test, tfidf_predictions))
print("TF-IDF Classification Report:\n", classification_report(y_test, tfidf_predictions))
print("TF-IDF Confusion Matrix:\n", confusion_matrix(y_test, tfidf_predictions))

# Visualizing the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, tfidf_predictions), annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('TF-IDF Confusion Matrix')
plt.show()

# Training the SVM model with Count Vectorizer features
svm_model_count = SVC(kernel='linear')
svm_model_count.fit(cn_x_train, y_train)

# Making predictions
count_predictions = svm_model_count.predict(cn_x_test)

# Evaluating the model
print("Count Vectorizer Accuracy:", accuracy_score(y_test, count_predictions))
print("Count Vectorizer Classification Report:\n", classification_report(y_test, count_predictions))
print("Count Vectorizer Confusion Matrix:\n", confusion_matrix(y_test, count_predictions))

# Visualizing the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, count_predictions), annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Count Vectorizer Confusion Matrix')
plt.show()

import pickle

# saving svm_model_tfidf  and  TF-IDF vectorizer
with open('svm_model_tfidf.pkl', 'wb') as model_file:
    pickle.dump(svm_model_tfidf, model_file)

with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:
    pickle.dump(tfidf, vectorizer_file)

